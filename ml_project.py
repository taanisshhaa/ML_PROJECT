# -*- coding: utf-8 -*-
"""ML PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16J3DPQlJfl30Vtm_tyVHLo52DJC59X5v

**Importing neccessary libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import LabelEncoder

"""**Adding the dataset into a dataframe variable**"""

# Checking for encoding of the .csv file

import chardet
with open ('Global YouTube Statistics.csv', 'rb') as file:
  result = chardet.detect(file.read(100000))
  encoding = result['encoding']
  print(f"Encoding of the file: {encoding}")

df = pd.read_csv('Global YouTube Statistics.csv', encoding = 'ISO-8859-1')

df

"""**EDA (Exploratory Data Analysis)**"""

df.describe()

df.shape

df.nunique()

df.isnull().sum()

# Displaying the heatmap

# METHOD 1: Converting categorical values to numeric values in a new duplicate dataframeto find the correaltion matrix and view the heatmap

df_numeric = df.copy()

le = LabelEncoder()
df_numeric['Youtuber_numeric'] = le.fit_transform(df_numeric['Youtuber'])
df_numeric['category_numeric'] = le.fit_transform(df_numeric['category'])
df_numeric['Title_numeric'] = le.fit_transform(df_numeric['Title'])
df_numeric['Country_numeric'] = le.fit_transform(df_numeric['Country'])
df_numeric['Abbreviation_numeric'] = le.fit_transform(df_numeric['Abbreviation'])
df_numeric['channel_type_numeric'] = le.fit_transform(df_numeric['channel_type'])
df_numeric['created_month_numeric'] = le.fit_transform(df_numeric['created_month'])

df_numeric = df_numeric.drop(['Youtuber', 'category', 'Title', 'Country', 'Abbreviation', 'channel_type', 'created_month'], axis = 1)

corr = df_numeric.corr()

plt.figure(figsize=(8,7))
sns.heatmap(corr, cmap='YlOrBr')

# METHOD 2: Dropping all non-numeric/categorical values from the dataframe and then viewing the heatmap

df_numeric = df_numeric.drop(['Youtuber_numeric', 'category_numeric', 'Title_numeric', 'Country_numeric', 'Abbreviation_numeric', 'channel_type_numeric', 'created_month_numeric'], axis = 1)

corr = df_numeric.corr()

sns.heatmap(corr, cmap='YlOrBr')

# Plotting numeric values using Scatter Plots

for i in df_numeric.columns:
  if(i!='video views'):
    plt.figure(figsize=(4,3))
    sns.scatterplot(x=i, y='video views', data=df_numeric)
    plt.show()

"""**Feature Engineering**"""

# Dropping unnecessary columns

df.drop(['Abbreviation', 'Latitude', 'Longitude'], axis=1, inplace=True)

df.head()

# Handling Missing values in the dataset

df.isnull().sum()

df['channel_type'] = df['channel_type'].replace(to_replace=np.nan, value='Other')

df['Country'] = df['Country'].replace(to_replace=np.nan, value='Other')

df = df.dropna(subset = ['category', 'created_year', 'created_month', 'created_date'])

df.isnull().sum()

columns_to_fill_with_mean = ['country_rank', 'channel_type_rank', 'video_views_for_the_last_30_days', 'subscribers_for_last_30_days', 'Gross tertiary education enrollment (%)', 'Population', 'Unemployment rate', 'Urban_population']

for col in columns_to_fill_with_mean:
  df[col] = df[col].fillna(df[col].mean())

df.isnull().sum()

# Detection and Removal of outliers using IQR(Inter-Quartile Range)

columns_for_IQR = ['rank', 'subscribers', 'video views', 'uploads', 'video_views_rank', 'country_rank', 'channel_type_rank', 'video_views_for_the_last_30_days', 'lowest_monthly_earnings', 'highest_monthly_earnings', 'lowest_yearly_earnings', 'highest_yearly_earnings', 'subscribers_for_last_30_days',  'Gross tertiary education enrollment (%)', 'Population', 'Unemployment rate', 'Urban_population']

for col in columns_for_IQR:
  Q1=df[col].quantile(0.25)
  Q3=df[col].quantile(0.75)
  IQR=Q3-Q1
  lower_bound=Q1-1.5*IQR
  upper_bound=Q3+1.5*IQR
  df=df[(df[col]>lower_bound) & (df[col]<upper_bound)]

df

# Scaling down the dataset using normalization

columns_for_MinMax = ['rank', 'subscribers', 'video views', 'uploads', 'video_views_rank', 'country_rank', 'channel_type_rank', 'video_views_for_the_last_30_days', 'lowest_monthly_earnings', 'highest_monthly_earnings', 'lowest_yearly_earnings', 'highest_yearly_earnings', 'subscribers_for_last_30_days',  'Gross tertiary education enrollment (%)', 'Population', 'Unemployment rate', 'Urban_population']

from sklearn.preprocessing import MinMaxScaler

scale = MinMaxScaler(feature_range=(0,100))

df[columns_for_MinMax] = scale.fit_transform(df[columns_for_MinMax])

df[columns_for_MinMax] = pd.DataFrame(df[columns_for_MinMax])

df

# One-Hot Encoding

df.nunique()

columns_for_encoding = ['Youtuber', 'category', 'Title', 'Country', 'channel_type', 'created_month']

df = pd.get_dummies(df, columns=columns_for_encoding)

for i in df.columns:
  print(i)

df

# Creating a new dataframe which has PCA (Principal Component Analysis)

X = df.drop(['video views'], axis = 1)

from sklearn.decomposition import PCA

pca = PCA(0.95)

X_pca = pca.fit_transform(X)

X_pca.shape

"""**Fitting the Model and Finding the accuracy**"""

# Using Linear Regression Algorithm

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df.drop(['video views'], axis = 1), df['video views'], test_size = 0.2, random_state = 42)

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Using Linear Regression Algorithm with X_pca dataframe

X_train, X_test, y_train, y_test = train_test_split(X_pca, df['video views'], test_size = 0.2, random_state = 42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred_pca = model.predict(X_test)

# Finding the accuracy of LinearRegression() model

from sklearn.metrics import mean_squared_error, r2_score

# Without PCA

MSE = mean_squared_error(y_test, y_pred)
Rsquare = r2_score(y_test, y_pred)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# With PCA

MSE = mean_squared_error(y_test, y_pred_pca)
Rsquare = r2_score(y_test, y_pred_pca)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# Using Random Forest Algorithm

X_train, X_test, y_train, y_test = train_test_split(df.drop(['video views'], axis = 1), df['video views'], test_size = 0.2, random_state = 42)

from sklearn.ensemble import RandomForestRegressor

model = RandomForestRegressor()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Using Random Forest Algorithm with X_pca dataframe

X_train, X_test, y_train, y_test = train_test_split(X_pca, df['video views'], test_size = 0.2, random_state = 42)

model = RandomForestRegressor()
model.fit(X_train, y_train)

y_pred_pca = model.predict(X_test)

# Finding the accuracy of RandomForestRegressor() model

# Without PCA

MSE = mean_squared_error(y_test, y_pred)
Rsquare = r2_score(y_test, y_pred)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# With PCA

MSE = mean_squared_error(y_test, y_pred_pca)
Rsquare = r2_score(y_test, y_pred_pca)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# Using Decision Tree Algorithm

X_train, X_test, y_train, y_test = train_test_split(df.drop(['video views'], axis = 1), df['video views'], test_size = 0.2, random_state = 42)

from sklearn.tree import DecisionTreeRegressor

model = DecisionTreeRegressor()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Using Decision Tree Algorithm with X_pca dataframe

X_train, X_test, y_train, y_test = train_test_split(X_pca, df['video views'], test_size = 0.2, random_state = 42)

model = DecisionTreeRegressor()
model.fit(X_train, y_train)

y_pred_pca = model.predict(X_test)

# Finding the accuracy of DecisionTreeRegressor() model

# Without PCA

MSE = mean_squared_error(y_test, y_pred)
Rsquare = r2_score(y_test, y_pred)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# With PCA

MSE = mean_squared_error(y_test, y_pred_pca)
Rsquare = r2_score(y_test, y_pred_pca)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# Using XGBoost Algorithm

import xgboost as xgb

X_train, X_test, y_train, y_test = train_test_split(df.drop(['video views'], axis = 1), df['video views'], test_size = 0.2, random_state = 42)

X_train = np.array(X_train)
X_test = np.array(X_test)
y_train = np.array(y_train)
y_test = np.array(y_test)

model = xgb.XGBRegressor()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Using XGBoost Algorithm with X_pca dataframe

X_train, X_test, y_train, y_test = train_test_split(X_pca, df['video views'], test_size = 0.2, random_state = 42)

model = xgb.XGBRegressor()
model.fit(X_train, y_train)

y_pred_pca = model.predict(X_test)

# Finding the accuracy of XGBRegressor() model

# Without PCA

MSE = mean_squared_error(y_test, y_pred)
Rsquare = r2_score(y_test, y_pred)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)

# Without PCA

MSE = mean_squared_error(y_test, y_pred_pca)
Rsquare = r2_score(y_test, y_pred_pca)

print("Mean Squared Error: ", MSE)
print("R-squared: ", Rsquare)